{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise05 : Distributed Training\n",
    "\n",
    "Here we change our sample (see \"[Exercise03 : Just Train in Your Working Machine](/notebooks/exercise03_train_simple.ipynb)\") for distributed training using multiple machines.\n",
    "\n",
    "In this exercise we use Horovod framework (https://github.com/horovod/horovod) using built-in ```azureml.train.dnn.TensorFlow``` estimator, but you can also configure using primitive ```azureml.core.ScriptRunConfig``` for the training with TensorFlow and Horovod. (See [here](https://tsmatz.wordpress.com/2019/01/17/azure-machine-learning-service-custom-amlcompute-and-runconfig-for-mxnet-distributed-training/) for sample script with TensorFlow and Horovod using ```azureml.core.ScriptRunConfig```.)\n",
    "\n",
    "*back to [index](/Readme.md)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change our original source code ```train.py``` (see \"[Exercise03 : Just Train in Your Working Machine](/notebooks/exercise03_train_simple.ipynb)\") as follows. The lines commented \"##### modified\" is modified lines.    \n",
    "After that, please add the following ```%%writefile``` at the beginning of the source code and run this cell.    \n",
    "This source code is saved as ```./script/train_horovod.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train_horovod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_horovod.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow as hvd ##### modified\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard\n",
    " \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        optimizer = hvd.DistributedOptimizer(optimizer) ##### modified\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "hvd.init() ##### modified\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.contrib.learn.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder if hvd.rank() == 0 else None, ##### modified\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    #max_steps=60000 * 2 / batch_size)\n",
    "    max_steps=(60000 * 2 / batch_size) // hvd.size(), ##### modified\n",
    "    hooks=[hvd.BroadcastGlobalVariablesHook(0)]) ##### modified\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "if hvd.rank() == 0 : ##### modified\n",
    "    model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "        export_dir_base = FLAGS.model_folder,\n",
    "        serving_input_receiver_fn = _my_serving_input_fn)\n",
    "    print('current working directory is ', os.getcwd())\n",
    "    print('model is saved ', model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on multiple machines (Horovod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Get workspace setting\n",
    "\n",
    "Before starting, you must read your configuration settings. (See \"[Exercise01 : Prepare Config Settings](/notebooks/exercise01_prepare_config.ipynb)\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/username/azure-ml-tensorflow-complete-sample/notebooks/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create multiple virtual machines (cluster)\n",
    "\n",
    "Create your new AML compute for distributed clusters. By enabling auto-scaling from 0 to 4, you can save money (all nodes are terminated) if it's inactive. see https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling \n",
    "If already exists, this script will get the existing cluster. The script below creates a cluster of  D2_v2 machines - vm_size='Standard_D2_v2',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new.\n",
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name='mycluster01')\n",
    "    print('found existing:', compute_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_D2_v2',\n",
    "        min_nodes=0,\n",
    "        max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, 'mycluster01', compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2018-12-10T23:58:49.117000+00:00', 'creationTime': '2018-12-10T23:58:14.928393+00:00', 'currentNodeCount': 0, 'errors': None, 'modifiedTime': '2018-12-10T23:59:03.412210+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 0, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "# get a status for the current cluster.\n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Prepare datastore\n",
    "\n",
    "You can mount your datastore (See \"[Exercise02 : Prepare Datastore](/notebooks/exercise02_prepare_datastore.ipynb)\") into your Batch AI compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "# get your datastore (See \"Exercise 02 : Prepare Datastore\")\n",
    "ds = Datastore.get(ws, datastore_name=\"myblob01\")\n",
    "ds_data = ds.path('tfdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Generate estimator **\n",
    "\n",
    "Run distributed training by Horovod using built-in ```azureml.train.dnn.TensorFlow``` estimator.    \n",
    "If you want to customize more detailed settings (other frameworks, custom images, etc), please use base ```azureml.train.estimator.Estimator``` (parent class).\n",
    "\n",
    "** Note : This estimator (```azureml.train.dnn.TensorFlow```) is an estimator in AML SDK, and not the same as ```tf.estimator.Estimator``` in TensorFlow. Do not confused for the terminology \"Estimator\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params={\n",
    "    '--data_folder': ds_data\n",
    "}\n",
    "estimator = TensorFlow(\n",
    "    source_directory='./script',\n",
    "    compute_target=compute_target,\n",
    "    script_params=script_params,\n",
    "    entry_script='train_horovod.py',\n",
    "    node_count=2,\n",
    "    process_count_per_node=1,\n",
    "    distributed_backend='mpi',\n",
    "    use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Run script and wait for completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: tf_distribued_1544486640614\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2018/12/11 00:04:08 Using acb_vol_86c50ced-41fd-4ff6-9367-dfb09b8c9363 as the home volume\n",
      "2018/12/11 00:04:08 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2018/12/11 00:04:09 Successfully set up Docker network: acb_default_network\n",
      "2018/12/11 00:04:09 Setting up Docker configuration...\n",
      "2018/12/11 00:04:10 Successfully set up Docker configuration\n",
      "2018/12/11 00:04:10 Logging in to registry: ws016106599079.azurecr.io\n",
      "2018/12/11 00:04:12 Successfully logged in\n",
      "2018/12/11 00:04:12 Executing step ID: acb_step_0. Working directory: '', Network: 'acb_default_network'\n",
      "2018/12/11 00:04:12 Obtaining source code and scanning for dependencies...\n",
      "2018/12/11 00:04:13 Successfully obtained source code and scanned for dependencies\n",
      "Sending build context to Docker daemon    150kB\n",
      "\n",
      "Step 1/13 : FROM mcr.microsoft.com/azureml/base:0.2.0\n",
      "0.2.0: Pulling from azureml/base\n",
      "3b37166ec614: Pulling fs layer\n",
      "504facff238f: Pulling fs layer\n",
      "ebbcacd28e10: Pulling fs layer\n",
      "c7fb3351ecad: Pulling fs layer\n",
      "2e3debadcbf7: Pulling fs layer\n",
      "7ff5eaad8a49: Pulling fs layer\n",
      "8697dd9e92dc: Pulling fs layer\n",
      "112403772eb3: Pulling fs layer\n",
      "0431a9485aa5: Pulling fs layer\n",
      "a8ab5d81aeba: Pulling fs layer\n",
      "c7fb3351ecad: Waiting\n",
      "2e3debadcbf7: Waiting\n",
      "7ff5eaad8a49: Waiting\n",
      "8697dd9e92dc: Waiting\n",
      "112403772eb3: Waiting\n",
      "0431a9485aa5: Waiting\n",
      "a8ab5d81aeba: Waiting\n",
      "ebbcacd28e10: Verifying Checksum\n",
      "ebbcacd28e10: Download complete\n",
      "c7fb3351ecad: Verifying Checksum\n",
      "c7fb3351ecad: Download complete\n",
      "2e3debadcbf7: Verifying Checksum\n",
      "2e3debadcbf7: Download complete\n",
      "3b37166ec614: Verifying Checksum\n",
      "3b37166ec614: Download complete\n",
      "504facff238f: Verifying Checksum\n",
      "504facff238f: Download complete\n",
      "3b37166ec614: Pull complete\n",
      "504facff238f: Pull complete\n",
      "ebbcacd28e10: Pull complete\n",
      "c7fb3351ecad: Pull complete\n",
      "2e3debadcbf7: Pull complete\n",
      "7ff5eaad8a49: Verifying Checksum\n",
      "7ff5eaad8a49: Download complete\n",
      "7ff5eaad8a49: Pull complete\n",
      "8697dd9e92dc: Verifying Checksum\n",
      "8697dd9e92dc: Download complete\n",
      "0431a9485aa5: Verifying Checksum\n",
      "0431a9485aa5: Download complete\n",
      "8697dd9e92dc: Pull complete\n",
      "112403772eb3: Verifying Checksum\n",
      "112403772eb3: Download complete\n",
      "a8ab5d81aeba: Verifying Checksum\n",
      "a8ab5d81aeba: Download complete\n",
      "112403772eb3: Pull complete\n",
      "0431a9485aa5: Pull complete\n",
      "a8ab5d81aeba: Pull complete\n",
      "Digest: sha256:bddfac8e9a4406c13f314cefefa24f3f67e959a8d8b26067096f7ade6f02ef12\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:0.2.0\n",
      " ---> b588362a9d48\n",
      "Step 2/13 : USER root\n",
      " ---> Running in 8bf43bc2c97a\n",
      "Removing intermediate container 8bf43bc2c97a\n",
      " ---> 1993b1ae19b8\n",
      "Step 3/13 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in e93c55fd27a9\n",
      "Removing intermediate container e93c55fd27a9\n",
      " ---> b3700b42d485\n",
      "Step 4/13 : WORKDIR /\n",
      " ---> Running in 352baad1b8dc\n",
      "Removing intermediate container 352baad1b8dc\n",
      " ---> cf72dd80b62f\n",
      "Step 5/13 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> d22ffafd6eb9\n",
      "Step 6/13 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.0; then conda install conda==4.4.11; fi\n",
      " ---> Running in 66898fac8f2b\n",
      "Removing intermediate container 66898fac8f2b\n",
      " ---> d106854e12d7\n",
      "Step 7/13 : COPY azureml-setup/mutated_conda_dependencies.yml azureml-setup/mutated_conda_dependencies.yml\n",
      " ---> 4dd4596addf5\n",
      "Step 8/13 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378 -f azureml-setup/mutated_conda_dependencies.yml && ldconfig\n",
      " ---> Running in b023fe374a7a\n",
      "Solving environment: ...working... done\n",
      "\u001b[91m\n",
      "ca-certificates-2018 | 124 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2018 | 124 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-18.1             | 1.8 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | ########9  |  89% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | #########8 |  98% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-8.2.0      | 7.6 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | ####8      |  49% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #######7   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########2  |  82% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########1  |  81% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #8         |  19% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ####       |  40% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ######6    |  67% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########2  |  82% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########2 |  93% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2p       | 3.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | #########2 |  92% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2018.11.29   | 146 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2018.11.29   | 146 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########6  |  86% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-40.6.2    | 604 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-40.6.2    | 604 KB    | ########4  |  84% \u001b[0m\u001b[91m\n",
      "setuptools-40.6.2    | 604 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ##7        |  28% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.32.3         | 35 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.32.3         | 35 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 920 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########9  |  90% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults (from -r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/4e/27a93da1484f06043f0a6b4d4f3e5ed7212c513eb0d2021cb434c4b2a29d/azureml_defaults-1.0.2-py2.py3-none-any.whl\n",
      "Collecting tensorflow==1.10.0 (from -r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
      "Collecting horovod==0.13.11 (from -r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/7d/8fc395fe9b2b3d4f769d3a778c6991fdd8c8f998df79b4967b4df5f8ec0d/horovod-0.13.11.tar.gz (103kB)\n",
      "Collecting azureml-core==1.0.2.* (from azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/ce/3443d87ba4735de037003413063b7d5d77b00543b787c495b0ab682be254/azureml_core-1.0.2-py2.py3-none-any.whl (651kB)\n",
      "Collecting applicationinsights>=0.11.0 (from azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/c8/7848a0dd85158930b859eb8be1e38fc76a91f0a040d491723ebb356d7358/applicationinsights-0.11.7-py2.py3-none-any.whl (56kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting tensorboard<1.11.0,>=1.10.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
      "Collecting protobuf>=3.6.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/f9/28787754923612ca9bfdffc588daa05580ed70698add063a5629d1a4209d/protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/64/2975e1d234c7bccf7a63e84452800f96aeecfd87d8310f77aa4afcda6bed/grpcio-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting setuptools<=39.1.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib/python3.6/site-packages (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2)) (0.32.3)\n",
      "Collecting six>=1.10.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/63/f505d2d4c21db849cf80bad517f0065a30be6b006b0a5637f1b95584a305/absl-py-0.6.1.tar.gz (94kB)\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting numpy<=1.14.5,>=1.13.3 (from tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "Collecting cffi>=1.4.0 (from horovod==0.13.11->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB)\n",
      "Collecting azure-cli-profile>=2.0.26 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/d3/fdc722a1b61857250a76027d6d73a50182c6d85132ddd65600a8993574ce/azure_cli_profile-2.1.2-py2.py3-none-any.whl\n",
      "Collecting azure-storage-common>=1.1.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/84/025ac436a6a1d5516d1a67887d7122b3b2ea04ba6b2d2c46fe949accb62b/azure_storage_common-1.4.0-py2.py3-none-any.whl (46kB)\n",
      "Collecting pytz (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl (506kB)\n",
      "Collecting python-dateutil>=2.7.3 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl (225kB)\n",
      "Collecting backports.tempfile (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
      "Collecting jsonpickle (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ce/97404d5aeb58e6155c216825c81b50f6eca8a5345c582317ae48391878f8/jsonpickle-1.0-py2.py3-none-any.whl\n",
      "Collecting azure-graphrbac>=0.40.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/a8/3d3d6fe8458b2b07bad10195c79928ea9ba87b5cc0c08903b387dd27c6f0/azure_graphrbac-0.53.0-py2.py3-none-any.whl (108kB)\n",
      "Collecting azure-storage-nspkg>=3.0.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/f6/054ace7b01c6c21b3b95a83c3997f7d6539d939a2c08c4f27f779128a030/azure_storage_nspkg-3.1.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.24,>=1.23 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl (133kB)\n",
      "Collecting ruamel.yaml<=0.15.51,>=0.15.35 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/7f/9bb3ba89ceab600c4a0ea75d638ea945215ca3458ac6528e0e39fa3254e4/ruamel.yaml-0.15.51-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/70/314fd97e8ea1d324f1f692cd06aa306f79e21500ba8248059dd3483ba14a/azure_mgmt_containerregistry-2.5.0-py2.py3-none-any.whl (494kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/d9/496b29857a252bc3fcc4bbda069c0eb64b537c8e8f7e342abb4053ba920f/azure_mgmt_storage-3.1.0-py2.py3-none-any.whl (696kB)\n",
      "Collecting azure-common>=1.1.12 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/d3/055ce7ad06459a415ff9ca210e04c6cbb51bd6564815b7c8ac34bf5a1c39/azure_common-1.1.16-py2.py3-none-any.whl\n",
      "Collecting azure-storage-blob>=1.1.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/b7/9b20c39bf411e896d110d01f2551e6e7b397fde6eb06b07293fe29705d13/azure_storage_blob-1.4.0-py2.py3-none-any.whl (75kB)\n",
      "Collecting docker (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/58/938fbc7acd98302ca4872f5eab8ab811498e342ab5aec0c1609f22e0aeda/docker-3.6.0-py2.py3-none-any.whl (131kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/60/c7/99b33c53cf3f20a97a4c4bfd3ab66dcc93d99da0a97cc9597aa36ae6bb62/cryptography-2.4.2-cp34-abi3-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting requests>=2.19.1 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting msrest>=0.5.1 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/40/70e545b7a5b0509273c6fe981118fb64e389fe013504b1c22a24fec4d1d9/msrest-0.6.2-py2.py3-none-any.whl (81kB)\n",
      "Collecting msrestazure>=0.4.33 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/6e/c41d6e2db39f4c6b819cea5b47c36c0fa0e7a931cd39b4c5f19713d28fd1/msrestazure-0.5.1-py2.py3-none-any.whl\n",
      "Collecting PyJWT (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Collecting ndg-httpsclient (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
      "Collecting SecretStorage<3.0.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/a5/0830cfe34a4cfd0d1c3c8b614ede1edb2aaf999091ac8548dd19cb352e79/SecretStorage-2.3.1.tar.gz\n",
      "Collecting pathspec (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
      "Collecting azure-mgmt-resource>=1.2.1 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/26/c0cb69dfac2e5b7125db034045b8bcf937cf1e8d3df2009a87c33d0959f5/azure_mgmt_resource-2.0.0-py2.py3-none-any.whl (698kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/71/9a20913e92771b3c23564f1bea54d376d09fb30a75585087c70b769d75c8/azure_mgmt_authorization-0.51.1-py2.py3-none-any.whl (111kB)\n",
      "Collecting azure-cli-core>=2.0.38 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/f0/507c83334d7ee7d588fdd1210b6f470446077c62f3e22fdb955f9d3396f8/azure_cli_core-2.0.52-py2.py3-none-any.whl (106kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111kB)\n",
      "Collecting contextlib2 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "Collecting pycparser (from cffi>=1.4.0->horovod==0.13.11->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Collecting azure-cli-command-modules-nspkg>=2.0.0 (from azure-cli-profile>=2.0.26->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/c9/cdeeeabc550848e2a07caa66cba28aa057d23b6feaa824ceafd32c3f2226/azure_cli_command_modules_nspkg-2.0.2-py2.py3-none-any.whl\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting azure-nspkg>=2.0.0 (from azure-storage-nspkg>=3.0.0->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting docker-pycreds>=0.3.0 (from docker->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Collecting websocket-client>=0.32.0 (from docker->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "Collecting idna>=2.1 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1)) (2018.11.29)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.19.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/94/e7/c250d122992e1561690d9c0f7856dadb79d61fd4bdd0e598087dce607f6c/requests_oauthlib-1.0.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "Collecting adal<2.0.0,>=0.6.0 (from msrestazure>=0.4.33->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/2f/14882b8dae0977e85577abde3065c141fb94dbb242adfb80e21797e4f7c9/adal-1.2.0-py2.py3-none-any.whl (52kB)\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/a1/7790cc85db38daa874f6a2e6308131b9953feb1367f2ae2d1123bb93a9f5/pyasn1-0.4.4-py2.py3-none-any.whl (72kB)\n",
      "Collecting PyOpenSSL (from ndg-httpsclient->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB)\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-resource>=1.2.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting pyyaml~=3.13 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "Collecting jmespath (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting colorama>=0.3.9 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
      "Collecting antlr4-python3-runtime; python_version >= \"3.0\" (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/96/aba01b2948ec67f237cd387c022820835ae0d8db5cab4bd404b351660b5e/antlr4-python3-runtime-4.7.1.tar.gz (111kB)\n",
      "Requirement already satisfied: pip in /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1)) (18.1)\n",
      "Collecting paramiko>=2.0.8 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\n",
      "Collecting knack==0.5.1 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/27/46/0a6d7471efcc519e392640f6933c0f644bbf602971e64797108292cb3623/knack-0.5.1-py2.py3-none-any.whl (50kB)\n",
      "Collecting pygments (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/41/4f900a7852e25bb9350b4e3ee8c4aba0ee32abefd401456962b25f954823/Pygments-2.3.0-py2.py3-none-any.whl (845kB)\n",
      "Collecting azure-cli-nspkg>=2.0.0 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/85/601ef6484bf7a722daa76a4383c4ccfd4980b74ed6c2895392f53ed210d5/azure_cli_nspkg-3.0.3-py2.py3-none-any.whl\n",
      "Collecting tabulate<=0.8.2,>=0.7.7 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\n",
      "Collecting humanfriendly>=4.7 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/79/1e/13d96248e3fcaa7777b61fa889feab44865c85e524bbd667acfa0d8b66e3/humanfriendly-4.17-py2.py3-none-any.whl (72kB)\n",
      "Collecting argcomplete>=1.8.0 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/31/88/ba8d8684a8a27749250c66ff7c2b408fdbc29b50da61200338ff9b2607bf/argcomplete-1.9.4-py2.py3-none-any.whl\n",
      "Collecting azure-cli-telemetry (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/4c/da5ebe9300ecdc850031372f81229383c46a70e83dee8e77f58aa6fd0546/azure_cli_telemetry-1.0.0-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/d1/ddd9cfea3e736399b97ded5c2dd62d1322adef4a72d816f1ed1049d6a179/oauthlib-2.1.0-py2.py3-none-any.whl (121kB)\n",
      "Collecting pynacl>=1.0.1 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
      "Collecting bcrypt>=3.1.3 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/09/905ec939994e2c49dcffff72f823802557f166b3815ea54c1db3671eed42/bcrypt-3.1.4-cp36-cp36m-manylinux1_x86_64.whl (54kB)\n",
      "Collecting portalocker==1.2.1 (from azure-cli-telemetry->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.hc_rqzxj.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/57/41/05e79e5516db1cc0c967b3202388cde729f871c871b0a07bf24ff11adfcf/portalocker-1.2.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: horovod, termcolor, absl-py, gast, SecretStorage, pathspec, pycparser, pyyaml, antlr4-python3-runtime, tabulate\n",
      "  Running setup.py bdist_wheel for horovod: started\n",
      "  Running setup.py bdist_wheel for horovod: finished with status 'error'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Complete output from command /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-82if505l/horovod/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-openme11 --python-tag cp36:\n",
      "  warning: no previously-included files found matching 'setup.pyc'\n",
      "  warning: no previously-included files matching 'yacctab.*' found under directory 'tests'\n",
      "  warning: no previously-included files matching 'lextab.*' found under directory 'tests'\n",
      "  warning: no previously-included files matching 'yacctab.*' found under directory 'examples'\n",
      "  warning: no previously-included files matching 'lextab.*' found under directory 'examples'\n",
      "  zip_safe flag not set; analyzing archive contents...\n",
      "  pycparser.ply.__pycache__.lex.cpython-36: module references __file__\n",
      "  pycparser.ply.__pycache__.lex.cpython-36: module MAY be using inspect.getsourcefile\n",
      "  pycparser.ply.__pycache__.yacc.cpython-36: module references __file__\n",
      "  pycparser.ply.__pycache__.yacc.cpython-36: module MAY be using inspect.getsourcefile\n",
      "  pycparser.ply.__pycache__.yacc.cpython-36: module MAY be using inspect.stack\n",
      "  pycparser.ply.__pycache__.ygen.cpython-36: module references __file__\n",
      "  \n",
      "  Installed /tmp/pip-install-82if505l/horovod/.eggs/pycparser-2.19-py3.6.egg\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/horovod\n",
      "  copying horovod/__init__.py -> build/lib.linux-x86_64-3.6/horovod\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/common\n",
      "  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/common\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/keras\n",
      "  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/keras\n",
      "  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/keras\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\n",
      "  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\n",
      "  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\n",
      "  running build_ext\n",
      "  gcc -pthread -B /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/compiler_compat -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -I/azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o\n",
      "  cc1plus: warning: command line option â€˜-Wstrict-prototypesâ€™ is valid for C/ObjC but not for C++\n",
      "  gcc -pthread -shared -B /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/compiler_compat -L/azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib -Wl,-rpath=/azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o -L/azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.so\n",
      "  INFO: Unable to build TensorFlow plugin, will skip it.\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 53, in check_tf_version\n",
      "      import tensorflow as tf\n",
      "  ModuleNotFoundError: No module named 'tensorflow'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 619, in build_extensions\n",
      "      abi_compile_flags = build_tf_extension(self, options)\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 445, in build_tf_extension\n",
      "      check_tf_version()\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 60, in check_tf_version\n",
      "      'import tensorflow failed, is it installed?\\n\\n%s' % traceback.format_exc())\n",
      "  distutils.errors.DistutilsPlatformError: import tensorflow failed, is it installed?\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 53, in check_tf_version\n",
      "      import tensorflow as tf\n",
      "  ModuleNotFoundError: No module named 'tensorflow'\n",
      "  \n",
      "  \n",
      "  INFO: Unable to build PyTorch plugin, will skip it.\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 491, in check_torch_version\n",
      "      import torch\n",
      "  ModuleNotFoundError: No module named 'torch'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 630, in build_extensions\n",
      "      build_torch_extension(self, options, abi_compile_flags)\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 546, in build_torch_extension\n",
      "      torch_version = check_torch_version()\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 494, in check_torch_version\n",
      "      'import torch failed, is it installed?\\n\\n%s' % traceback.format_exc())\n",
      "  distutils.errors.DistutilsPlatformError: import torch failed, is it installed?\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-82if505l/horovod/setup.py\", line 491, in check_torch_version\n",
      "      import torch\n",
      "  ModuleNotFoundError: No module named 'torch'\n",
      "  \n",
      "  \n",
      "  error: Neither TensorFlow nor PyTorch plugins were built. See errors above.\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[91m  Failed building wheel for horovod\n",
      "\u001b[0m  Running setup.py clean for horovod\n",
      "  Running setup.py bdist_wheel for termcolor: started\n",
      "  Running setup.py bdist_wheel for termcolor: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py: started\n",
      "  Running setup.py bdist_wheel for absl-py: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/ea/5e/e36e1b8739e78cd2eba0a08fdc602c2b16a4b263912af8cb64\n",
      "  Running setup.py bdist_wheel for gast: started\n",
      "  Running setup.py bdist_wheel for gast: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for SecretStorage: started\n",
      "  Running setup.py bdist_wheel for SecretStorage: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/5b/1b/be8c8a830a0243af85b2946a0aece2c6743d7f7f946977ed67\n",
      "  Running setup.py bdist_wheel for pathspec: started\n",
      "  Running setup.py bdist_wheel for pathspec: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
      "  Running setup.py bdist_wheel for pycparser: started\n",
      "  Running setup.py bdist_wheel for pycparser: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "  Running setup.py bdist_wheel for antlr4-python3-runtime: started\n",
      "  Running setup.py bdist_wheel for antlr4-python3-runtime: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/f6/18/ad300e691236a3408a99edc750484b56e8d6b11b2c38eacb10\n",
      "  Running setup.py bdist_wheel for tabulate: started\n",
      "  Running setup.py bdist_wheel for tabulate: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\n",
      "Successfully built termcolor absl-py gast SecretStorage pathspec pycparser pyyaml antlr4-python3-runtime tabulate\n",
      "Failed to build horovod\n",
      "\u001b[91mazure-cli-core 2.0.52 has requirement wheel==0.30.0, but you'll have wheel 0.32.3 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: azure-nspkg, azure-cli-nspkg, azure-cli-command-modules-nspkg, pycparser, cffi, asn1crypto, six, idna, cryptography, PyOpenSSL, python-dateutil, urllib3, chardet, requests, PyJWT, adal, pyyaml, jmespath, colorama, antlr4-python3-runtime, oauthlib, requests-oauthlib, isodate, msrest, pynacl, pyasn1, bcrypt, paramiko, pygments, tabulate, argcomplete, knack, humanfriendly, applicationinsights, portalocker, azure-cli-telemetry, msrestazure, azure-mgmt-nspkg, azure-common, azure-mgmt-resource, azure-cli-core, azure-cli-profile, azure-storage-common, pytz, backports.weakref, backports.tempfile, jsonpickle, azure-graphrbac, azure-storage-nspkg, ruamel.yaml, azure-mgmt-containerregistry, azure-mgmt-storage, azure-storage-blob, docker-pycreds, websocket-client, docker, ndg-httpsclient, SecretStorage, pathspec, azure-mgmt-authorization, azure-mgmt-keyvault, contextlib2, azureml-core, azureml-defaults, termcolor, setuptools, protobuf, markdown, werkzeug, numpy, tensorboard, grpcio, absl-py, astor, gast, tensorflow, horovod\n",
      "  Found existing installation: setuptools 40.6.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling setuptools-40.6.2:\n",
      "      Successfully uninstalled setuptools-40.6.2\n",
      "  Running setup.py install for horovod: started\n",
      "    Running setup.py install for horovod: finished with status 'done'\n",
      "Successfully installed PyJWT-1.7.1 PyOpenSSL-18.0.0 SecretStorage-2.3.1 absl-py-0.6.1 adal-1.2.0 antlr4-python3-runtime-4.7.1 applicationinsights-0.11.7 argcomplete-1.9.4 asn1crypto-0.24.0 astor-0.7.1 azure-cli-command-modules-nspkg-2.0.2 azure-cli-core-2.0.52 azure-cli-nspkg-3.0.3 azure-cli-profile-2.1.2 azure-cli-telemetry-1.0.0 azure-common-1.1.16 azure-graphrbac-0.53.0 azure-mgmt-authorization-0.51.1 azure-mgmt-containerregistry-2.5.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-2.0.0 azure-mgmt-storage-3.1.0 azure-nspkg-3.0.2 azure-storage-blob-1.4.0 azure-storage-common-1.4.0 azure-storage-nspkg-3.1.0 azureml-core-1.0.2 azureml-defaults-1.0.2 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.1.4 cffi-1.11.5 chardet-3.0.4 colorama-0.4.1 contextlib2-0.5.5 cryptography-2.4.2 docker-3.6.0 docker-pycreds-0.4.0 gast-0.2.0 grpcio-1.17.0 horovod-0.13.11 humanfriendly-4.17 idna-2.8 isodate-0.6.0 jmespath-0.9.3 jsonpickle-1.0 knack-0.5.1 markdown-3.0.1 msrest-0.6.2 msrestazure-0.5.1 ndg-httpsclient-0.5.1 numpy-1.14.5 oauthlib-2.1.0 paramiko-2.4.2 pathspec-0.5.9 portalocker-1.2.1 protobuf-3.6.1 pyasn1-0.4.4 pycparser-2.19 pygments-2.3.0 pynacl-1.3.0 python-dateutil-2.7.5 pytz-2018.7 pyyaml-3.13 requests-2.21.0 requests-oauthlib-1.0.0 ruamel.yaml-0.15.51 setuptools-39.1.0 six-1.12.0 tabulate-0.8.2 tensorboard-1.10.0 tensorflow-1.10.0 termcolor-1.1.0 urllib3-1.23 websocket-client-0.54.0 werkzeug-0.14.1\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "Removing intermediate container b023fe374a7a\n",
      " ---> 8dcc2d3fc3b6\n",
      "Step 9/13 : ENV PATH /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/bin:$PATH\n",
      " ---> Running in 3203df8a3b38\n",
      "Removing intermediate container 3203df8a3b38\n",
      " ---> 7e400b9ead92\n",
      "Step 10/13 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_c41295f9cf92073d57b356b8eef29378/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in d1044350fbc2\n",
      "Removing intermediate container d1044350fbc2\n",
      " ---> 1f20784e6834\n",
      "Step 11/13 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n",
      " ---> 505c684cbe57\n",
      "Step 12/13 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"https://mmlspark.azureedge.net/maven\" \"--packages\" \"com.microsoft.ml.spark:mmlspark_2.11:0.12\" \"--conf\" \"spark.app.name=Azure ML Experiment\" \"--conf\" \"spark.yarn.maxAppAttempts=1\" \"--driver-java-options\" \"-Dlog4j.configuration=file:./azureml-setup/log4j.properties\" \"--conf\" \"spark.eventLog.enabled=true\" \"--conf\" \"spark.eventLog.dir=./azureml-logs\" /azureml-setup/spark_cache.py'; fi\n",
      " ---> Running in 7ec77086377c\n",
      "Removing intermediate container 7ec77086377c\n",
      " ---> 50731c69c220\n",
      "Step 13/13 : CMD [\"bash\"]\n",
      " ---> Running in 01cdcca502b1\n",
      "Removing intermediate container 01cdcca502b1\n",
      " ---> c330aa7e6191\n",
      "Successfully built c330aa7e6191\n",
      "Successfully tagged ws016106599079.azurecr.io/azureml/azureml_4c56258fd6ff499504c10db6bea8ec3e:latest\n",
      "2018/12/11 00:06:59 Executing step ID: acb_step_1. Working directory: '', Network: 'acb_default_network'\n",
      "2018/12/11 00:06:59 Pushing image: ws016106599079.azurecr.io/azureml/azureml_4c56258fd6ff499504c10db6bea8ec3e:latest, attempt 1\n",
      "The push refers to repository [ws016106599079.azurecr.io/azureml/azureml_4c56258fd6ff499504c10db6bea8ec3e]\n",
      "5e5f500b1543: Preparing\n",
      "335a3102dc4a: Preparing\n",
      "8b57e95e5de9: Preparing\n",
      "a469c2956d9b: Preparing\n",
      "74f83c7b3c3e: Preparing\n",
      "e7ff3c8d56c2: Preparing\n",
      "ce619be2681d: Preparing\n",
      "db9d63ec4abf: Preparing\n",
      "2fc9fc8da07e: Preparing\n",
      "150ddd7a1544: Preparing\n",
      "75b79e19929c: Preparing\n",
      "4775b2f378bb: Preparing\n",
      "883eafdbe580: Preparing\n",
      "19d043c86cbc: Preparing\n",
      "8823818c4748: Preparing\n",
      "e7ff3c8d56c2: Waiting\n",
      "ce619be2681d: Waiting\n",
      "db9d63ec4abf: Waiting\n",
      "2fc9fc8da07e: Waiting\n",
      "150ddd7a1544: Waiting\n",
      "75b79e19929c: Waiting\n",
      "4775b2f378bb: Waiting\n",
      "883eafdbe580: Waiting\n",
      "19d043c86cbc: Waiting\n",
      "8823818c4748: Waiting\n",
      "74f83c7b3c3e: Pushed\n",
      "5e5f500b1543: Pushed\n",
      "a469c2956d9b: Pushed\n",
      "8b57e95e5de9: Pushed\n",
      "ce619be2681d: Pushed\n",
      "2fc9fc8da07e: Pushed\n",
      "150ddd7a1544: Pushed\n",
      "e7ff3c8d56c2: Pushed\n",
      "75b79e19929c: Pushed\n",
      "883eafdbe580: Pushed\n",
      "4775b2f378bb: Pushed\n",
      "19d043c86cbc: Pushed\n",
      "335a3102dc4a: Pushed\n",
      "8823818c4748: Pushed\n",
      "db9d63ec4abf: Pushed\n",
      "latest: digest: sha256:22760bb253578ad5f0edbdd3358a6955c2c88a7ddcae7a612c99aef03193bd6e size: 3458\n",
      "2018/12/11 00:08:32 Successfully pushed image: ws016106599079.azurecr.io/azureml/azureml_4c56258fd6ff499504c10db6bea8ec3e:latest\n",
      "2018/12/11 00:08:32 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 166.780773)\n",
      "2018/12/11 00:08:32 Populating digests for step ID: acb_step_0...\n",
      "The following dependencies were found:\n",
      "- image:\n",
      "    registry: ws016106599079.azurecr.io\n",
      "    repository: azureml/azureml_4c56258fd6ff499504c10db6bea8ec3e\n",
      "    tag: latest\n",
      "    digest: sha256:22760bb253578ad5f0edbdd3358a6955c2c88a7ddcae7a612c99aef03193bd6e\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: 0.2.0\n",
      "    digest: sha256:bddfac8e9a4406c13f314cefefa24f3f67e959a8d8b26067096f7ade6f02ef12\n",
      "  git: {}\n",
      "\n",
      "2018/12/11 00:08:34 Successfully populated digests for step ID: acb_step_0\n",
      "2018/12/11 00:08:34 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 93.357029)\n",
      "Run ID: cac was successful after 4m29s\n",
      "\n",
      "Streaming azureml-logs/60_control_log_rank_0.txt\n",
      "================================================\n",
      "\n",
      "This is an MPI job. Rank:0\n",
      "Streaming log file azureml-logs/60_control_log_rank_0.txt\n",
      "Streaming log file azureml-logs/80_driver_log_rank_0.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log_rank_0.txt\n",
      "===============================================\n",
      "\n",
      "WARNING:tensorflow:From train_horovod.py:189: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "2018-12-11 00:17:48.306989: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "current working directory is  /mnt/batch/tasks/shared/LS_root/jobs/ws01/azureml/tf_distribued_1544486640614/mounts/azureml_project_share/azureml/tf_distribued_1544486640614\n",
      "model is saved  b'./outputs/1544487483'\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.1007075309753418 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: tf_distribued_1544486640614\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'tf_distribued_1544486640614',\n",
       " 'target': 'mycluster01',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2018-12-11T00:14:13.697925Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'a956a4e2-8f1b-4d44-8581-30bbefb4d480'},\n",
       " 'runDefinition': {'Script': 'train_horovod.py',\n",
       "  'Arguments': ['--data_folder',\n",
       "   '$AZUREML_DATAREFERENCE_fc58254fa9c942f7a384af1aa8253e07'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 3,\n",
       "  'Target': 'mycluster01',\n",
       "  'DataReferences': {'fc58254fa9c942f7a384af1aa8253e07': {'DataStoreName': 'myblob01',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': 'tfdata',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 2,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'tensorflow==1.10.0',\n",
       "        'horovod==0.13.11']}]},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.2.0',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 2},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://ws015719760712.blob.core.windows.net/azureml/ExperimentRun/tf_distribued_1544486640614/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=5g%2FdD54Vzs7d79YP53BOgRl%2BYgTixoHH27dDrsA3D%2BU%3D&st=2018-12-11T00%3A08%3A19Z&se=2018-12-11T08%3A18%3A19Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_0.txt': 'https://ws015719760712.blob.core.windows.net/azureml/ExperimentRun/tf_distribued_1544486640614/azureml-logs/60_control_log_rank_0.txt?sv=2018-03-28&sr=b&sig=7bjJxs%2BzuV089Uwehenh1ZzjaP0AXfi9F%2F82nSMlJOw%3D&st=2018-12-11T00%3A08%3A19Z&se=2018-12-11T08%3A18%3A19Z&sp=r',\n",
       "  'azureml-logs/60_control_log_rank_1.txt': 'https://ws015719760712.blob.core.windows.net/azureml/ExperimentRun/tf_distribued_1544486640614/azureml-logs/60_control_log_rank_1.txt?sv=2018-03-28&sr=b&sig=t%2F9qbedZcAN4dL7ErjiaVA46OXh8o4LwbWFr3cVpo8k%3D&st=2018-12-11T00%3A08%3A19Z&se=2018-12-11T08%3A18%3A19Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_0.txt': 'https://ws015719760712.blob.core.windows.net/azureml/ExperimentRun/tf_distribued_1544486640614/azureml-logs/80_driver_log_rank_0.txt?sv=2018-03-28&sr=b&sig=URjHtvPhgOA9zTT2uHoubAljPJOzrvTm2Wxgm3BOFhM%3D&st=2018-12-11T00%3A08%3A19Z&se=2018-12-11T08%3A18%3A19Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_1.txt': 'https://ws015719760712.blob.core.windows.net/azureml/ExperimentRun/tf_distribued_1544486640614/azureml-logs/80_driver_log_rank_1.txt?sv=2018-03-28&sr=b&sig=PYtd5RbWhJUCigcUf7uUk20LDh9yAdizcB74OEQJM0E%3D&st=2018-12-11T00%3A08%3A19Z&se=2018-12-11T08%3A18%3A19Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://ws015719760712.blob.core.windows.net/azureml/ExperimentRun/tf_distribued_1544486640614/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=KYgfXJzMmgTm1v9P%2B1EuXvor8hYHQtR4ikboOnseMo4%3D&st=2018-12-11T00%3A08%3A19Z&se=2018-12-11T08%3A18%3A19Z&sp=r'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "exp = Experiment(workspace=ws, name='tf_distribued')\n",
    "run = exp.submit(estimator)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/20_image_build_log.txt',\n",
       " 'azureml-logs/60_control_log_rank_0.txt',\n",
       " 'azureml-logs/60_control_log_rank_1.txt',\n",
       " 'azureml-logs/80_driver_log_rank_0.txt',\n",
       " 'logs/checkpoint',\n",
       " 'logs/model.ckpt-0.meta',\n",
       " 'logs/events.out.tfevents.1544487468.86ceebae67124cd6be30443940e3e727000000',\n",
       " 'logs/graph.pbtxt',\n",
       " 'logs/model.ckpt-0.data-00000-of-00001',\n",
       " 'logs/model.ckpt-0.index',\n",
       " 'azureml-logs/80_driver_log_rank_1.txt',\n",
       " 'logs/model.ckpt-600.index',\n",
       " 'logs/model.ckpt-600.meta',\n",
       " 'logs/model.ckpt-600.data-00000-of-00001',\n",
       " 'logs/eval/events.out.tfevents.1544487483.86ceebae67124cd6be30443940e3e727000000',\n",
       " 'outputs/1544487483/saved_model.pb',\n",
       " 'outputs/1544487483/variables/variables.data-00000-of-00001',\n",
       " 'outputs/1544487483/variables/variables.index',\n",
       " 'driver_log',\n",
       " 'azureml-logs/azureml.log',\n",
       " 'azureml-logs/56_batchai_stderr.txt',\n",
       " 'azureml-logs/55_batchai_execution-tvm-829305193_1-20181211t001024z.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please change ```1544487483``` to meet previous results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file(\n",
    "    name='outputs/1544487483/saved_model.pb',\n",
    "    output_file_path='distributed_model/saved_model.pb')\n",
    "run.download_file(\n",
    "    name='outputs/1544487483/variables/variables.data-00000-of-00001',\n",
    "    output_file_path='distributed_model/variables/variables.data-00000-of-00001')\n",
    "run.download_file(\n",
    "    name='outputs/1544487483/variables/variables.index',\n",
    "    output_file_path='distributed_model/variables/variables.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./distributed_model/variables/variables\n",
      "Predicted:  [7, 2, 1]\n",
      "Actual   :  [7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Read data by tensor\n",
    "dataset = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "data_org = iterator.get_next()\n",
    "data_exam = tf.parse_single_example(\n",
    "    data_org,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "data_image.set_shape([784])\n",
    "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "\n",
    "# Run tensor and generate data\n",
    "with tf.Session() as sess:\n",
    "    image_arr = []\n",
    "    label_arr = []\n",
    "    for i in range(3):\n",
    "        image, label = sess.run([data_image, data_label])\n",
    "        image_arr.append(image)\n",
    "        label_arr.append(label)\n",
    "\n",
    "# Predict\n",
    "pred_fn = tf.contrib.predictor.from_saved_model('./distributed_model')\n",
    "pred = pred_fn({'inputs': image_arr})\n",
    "\n",
    "print('Predicted: ', pred['classes'].tolist())\n",
    "print('Actual   : ', label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.    \n",
    "But if you want to clean up, please run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster (nbodes) and remove from AML workspace\n",
    "mycompute = AmlCompute(workspace=ws, name='mycluster01')\n",
    "mycompute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
