{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise04 : Train on Remote GPU Virtual Machine\n",
    "\n",
    "Now we run our previous sample (see \"[Exercise03 : Just Train in Your Working Machine](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/blob/master/notebooks/exercise03_train_simple.ipynb)\") on remote virtual machine with GPU utilized.    \n",
    "Here we use remote virtual machine and conda virtual environment, but you can also use Batch AI pool sharing in your team, or run on your favorite docker images.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add the following ```%%writefile``` at the beginning of the source code in \"[Exercise03 : Just Train in Your Working Machine](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/blob/master/notebooks/exercise03_train_simple.ipynb)\", and run this cell.    \n",
    "Then this source code is saved as ```./script/train.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard\n",
    " \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.contrib.learn.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on remote VM\n",
    "\n",
    "Now let's start to integrate with AML services and run training on remote virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Get workspace setting\n",
    "\n",
    "Before starting, you must read your configuration settings. (See \"[Exercise01 : Prepare Config Settings](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/blob/master/notebooks/exercise01_prepare_config.ipynb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/tsmatsuz/Tutorial/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create new remote virtual machine\n",
    "\n",
    "Create your new Data Science Virtual Machine (which is pre-configured for data science) with **GPU** (NC6).    \n",
    "If you chose AML workspace location (region) which doesn't support GPU VM instance, please provide ```location``` argument in ```provisioning_configuration```.\n",
    "\n",
    "e.g, ```dsvm_config = DsvmCompute.provisioning_configuration(vm_size='STANDARD_NC6', location='east-us')```\n",
    "\n",
    "If already exists, this script will get the existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new.\n",
      "Creating.............................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import DsvmCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    dsvm_compute = DsvmCompute(workspace=ws, name='mydsvm01')\n",
    "    print('found existing:', dsvm_compute.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    dsvm_config = DsvmCompute.provisioning_configuration(vm_size='STANDARD_NC6')\n",
    "    dsvm_compute = DsvmCompute.create(ws, name='mydsvm01', provisioning_configuration=dsvm_config)\n",
    "    dsvm_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Generate data reference config\n",
    "\n",
    "You can configure to automatically download your dataset (including train.tfrecords, test.tfrecords) from your ```Datastore``` in your compute target.    \n",
    "See \"[Exercise02 : Prepare Datastore](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/blob/master/notebooks/exercise02_prepare_datastore.ipynb)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "# get your datastore (See \"Exercise 02 : Prepare Datastore\")\n",
    "ds = Datastore.get(ws, datastore_name=\"myblob01\")\n",
    "\n",
    "# generate data reference configuration\n",
    "dr_conf = DataReferenceConfiguration(\n",
    "    datastore_name=ds.name,\n",
    "    path_on_datastore='tfdata',\n",
    "    mode='download', # set 'mount' if you mount folder instead of downloading (but it's not supported in remote VM)\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Generate VM config\n",
    "\n",
    "Here we build a conda environment and set dependencies. In this configuration, we use previous data reference configuration. (The data is copied automatically.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "run_config = RunConfiguration(framework=\"python\")\n",
    "run_config.target = dsvm_compute.name\n",
    "run_config.data_references = {ds.name: dr_conf}\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['tensorflow-gpu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Run script and wait for completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: matsu_test1116_02_1542332931636\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Running ['conda', '--version']\n",
      "Creating Conda environment...\n",
      "Logging experiment preparation status in history service.\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "numpy-base-1.15.4    | 4.2 MB    | ########## | 100% \n",
      "_tflow_select-2.1.0  | 2 KB      | ########## | 100% \n",
      "astor-0.7.1          | 43 KB     | ########## | 100% \n",
      "cupti-9.2.148        | 1.7 MB    | ########## | 100% \n",
      "tensorflow-1.12.0    | 3 KB      | ########## | 100% \n",
      "cudatoolkit-9.2      | 351.0 MB  | ########## | 100% \n",
      "gast-0.2.0           | 15 KB     | ########## | 100% \n",
      "cudnn-7.2.1          | 322.8 MB  | ########## | 100% \n",
      "numpy-1.15.4         | 35 KB     | ########## | 100% \n",
      "libprotobuf-3.6.1    | 4.1 MB    | ########## | 100% \n",
      "grpcio-1.14.1        | 1.0 MB    | ########## | 100% \n",
      "h5py-2.8.0           | 1.1 MB    | ########## | 100% \n",
      "mkl_fft-1.0.6        | 150 KB    | ########## | 100% \n",
      "c-ares-1.15.0        | 98 KB     | ########## | 100% \n",
      "absl-py-0.6.1        | 152 KB    | ########## | 100% \n",
      "termcolor-1.1.0      | 7 KB      | ########## | 100% \n",
      "protobuf-3.6.1       | 616 KB    | ########## | 100% \n",
      "tensorboard-1.12.0   | 3.1 MB    | ########## | 100% \n",
      "keras-preprocessing- | 52 KB     | ########## | 100% \n",
      "markdown-3.0.1       | 107 KB    | ########## | 100% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "werkzeug-0.14.1      | 423 KB    | ########## | 100% \n",
      "tensorflow-base-1.12 | 216.9 MB  | ########## | 100% \n",
      "tensorflow-gpu-1.12. | 2 KB      | ########## | 100% \n",
      "keras-applications-1 | 49 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults==0.1.74 (from -r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/62/57/7fb3c74814864e23925db862c69b373e830870c01a4b2d061f7495918e4d/azureml_defaults-0.1.74-py2.py3-none-any.whl\n",
      "Collecting azureml-core==0.1.74.* (from azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/e1/062c248f174389615422ad85c1fbd56b686c185743758fc5983957610bcf/azureml_core-0.1.74-py2.py3-none-any.whl\n",
      "Collecting applicationinsights>=0.11.0 (from azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/e3/c8/7848a0dd85158930b859eb8be1e38fc76a91f0a040d491723ebb356d7358/applicationinsights-0.11.7-py2.py3-none-any.whl\n",
      "Collecting azure-cli-core>=2.0.38 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/18/fa/4adcb8d2a7683ba972eb2b56d68f21cd0d5b43222c368c5ee6bc38cf2e4d/azure_cli_core-2.0.50-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.11.0 in /data/home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1)) (1.11.0)\n",
      "Collecting msrestazure>=0.4.33 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/62/6e/c41d6e2db39f4c6b819cea5b47c36c0fa0e7a931cd39b4c5f19713d28fd1/msrestazure-0.5.1-py2.py3-none-any.whl\n",
      "Collecting ruamel.yaml<=0.15.51,>=0.15.35 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/7f/9bb3ba89ceab600c4a0ea75d638ea945215ca3458ac6528e0e39fa3254e4/ruamel.yaml-0.15.51-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting azure-storage-nspkg>=3.0.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/f6/054ace7b01c6c21b3b95a83c3997f7d6539d939a2c08c4f27f779128a030/azure_storage_nspkg-3.1.0-py2.py3-none-any.whl\n",
      "Collecting docker (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/76/b8091dc6d9db038af62ae88f228da656a84632cf5d7a84dcf54c613d3fd0/docker-3.5.1-py2.py3-none-any.whl\n",
      "Collecting PyJWT (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/93/d1/3378cc8184a6524dc92993090ee8b4c03847c567e298305d6cf86987e005/PyJWT-1.6.4-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-storage>=1.5.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/d9/496b29857a252bc3fcc4bbda069c0eb64b537c8e8f7e342abb4053ba920f/azure_mgmt_storage-3.1.0-py2.py3-none-any.whl\n",
      "Collecting jsonpickle (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/ce/97404d5aeb58e6155c216825c81b50f6eca8a5345c582317ae48391878f8/jsonpickle-1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d1/e8887811e8e5ab336e77db7cfb9f451bdae69a8ed97f53cc2cd11fdcac8f/azure_mgmt_containerregistry-2.4.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.7.3 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl\n",
      "Collecting ndg-httpsclient (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
      "Collecting azure-mgmt-resource>=1.2.1 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/26/c0cb69dfac2e5b7125db034045b8bcf937cf1e8d3df2009a87c33d0959f5/azure_mgmt_resource-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-authorization>=0.40.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/20/91/cad6fb2eb9ad106c8d5bd45514af2772c956e921f57b85db6bd0919923e7/azure_mgmt_authorization-0.51.0-py2.py3-none-any.whl\n",
      "Collecting azure-graphrbac>=0.40.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/97/84/b4558e3f469c67497a2a5eaeb05321f91b1ee2d1205992a33f001d9c4bf9/azure_graphrbac-0.52.0-py2.py3-none-any.whl\n",
      "Collecting azure-storage-blob>=1.1.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/b7/9b20c39bf411e896d110d01f2551e6e7b397fde6eb06b07293fe29705d13/azure_storage_blob-1.4.0-py2.py3-none-any.whl\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/18/1583e40c38ff8572c42e56ce17b95357a9ebb91375cfbd7aad63cac9a32e/cryptography-2.4.1-cp34-abi3-manylinux1_x86_64.whl\n",
      "Collecting requests>=2.19.1 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl\n",
      "Collecting azure-common>=1.1.12 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/d3/055ce7ad06459a415ff9ca210e04c6cbb51bd6564815b7c8ac34bf5a1c39/azure_common-1.1.16-py2.py3-none-any.whl\n",
      "Collecting SecretStorage<3.0.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "Collecting msrest>=0.5.1 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/8e/05c45ff0c0f293e8d044030a0007a16ece0d39dbc7fa6bb911a2f53b649a/msrest-0.6.1-py2.py3-none-any.whl\n",
      "Collecting azure-cli-profile>=2.0.26 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/d3/fdc722a1b61857250a76027d6d73a50182c6d85132ddd65600a8993574ce/azure_cli_profile-2.1.2-py2.py3-none-any.whl\n",
      "Collecting backports.tempfile (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
      "Collecting azure-storage-common>=1.1.0 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/73/84/025ac436a6a1d5516d1a67887d7122b3b2ea04ba6b2d2c46fe949accb62b/azure_storage_common-1.4.0-py2.py3-none-any.whl\n",
      "Collecting pytz (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl\n",
      "Collecting contextlib2 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.24,>=1.23 (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl\n",
      "Collecting pathspec (from azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "Collecting azure-cli-telemetry (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/71/4c/da5ebe9300ecdc850031372f81229383c46a70e83dee8e77f58aa6fd0546/azure_cli_telemetry-1.0.0-py2.py3-none-any.whl\n",
      "Collecting knack==0.4.5 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/02/89/1ea05831b95d6bdc8880acdd0304a915156eb5f94aeab0fd36649a940c45/knack-0.4.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pip in /data/home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1)) (18.1)\n",
      "Collecting humanfriendly>=4.7 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/79/1e/13d96248e3fcaa7777b61fa889feab44865c85e524bbd667acfa0d8b66e3/humanfriendly-4.17-py2.py3-none-any.whl\n",
      "Collecting colorama>=0.3.9 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/0a/93/6e8289231675d561d476d656c2ee3a868c1cca207e16c118d4503b25e2bf/colorama-0.4.0-py2.py3-none-any.whl\n",
      "Collecting antlr4-python3-runtime; python_version >= \"3.0\" (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "Collecting wheel==0.30.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/80/16a85b47702a1f47a63c104c91abdd0a6704ee8ae3b4ce4afc49bc39f9d9/wheel-0.30.0-py2.py3-none-any.whl (49kB)\n",
      "Collecting paramiko>=2.0.8 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl\n",
      "Collecting pyyaml~=3.13 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "Collecting argcomplete>=1.8.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/31/88/ba8d8684a8a27749250c66ff7c2b408fdbc29b50da61200338ff9b2607bf/argcomplete-1.9.4-py2.py3-none-any.whl\n",
      "Collecting adal>=1.2.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/2f/14882b8dae0977e85577abde3065c141fb94dbb242adfb80e21797e4f7c9/adal-1.2.0-py2.py3-none-any.whl\n",
      "Collecting tabulate<=0.8.2,>=0.7.7 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "Collecting pyopenssl>=17.1.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-cli-nspkg>=2.0.0 (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/85/601ef6484bf7a722daa76a4383c4ccfd4980b74ed6c2895392f53ed210d5/azure_cli_nspkg-3.0.3-py2.py3-none-any.whl\n",
      "Collecting pygments (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/02/ee/b6e02dc6529e82b75bb06823ff7d005b141037cb1416b10c6f00fc419dca/Pygments-2.2.0-py2.py3-none-any.whl\n",
      "Collecting jmespath (from azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-keyvault>=0.40.0->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting azure-nspkg>=2.0.0 (from azure-storage-nspkg>=3.0.0->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting websocket-client>=0.32.0 (from docker->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl\n",
      "Collecting docker-pycreds>=0.3.0 (from docker->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ea/bf/7e70aeebc40407fbdb96fa9f79fc8e4722ea889a99378303e3bcc73f4ab5/docker_pycreds-0.3.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/a1/7790cc85db38daa874f6a2e6308131b9953feb1367f2ae2d1123bb93a9f5/pyasn1-0.4.4-py2.py3-none-any.whl\n",
      "Collecting idna>=2.1 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl\n",
      "Collecting cffi!=1.11.3,>=1.7 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1)) (2018.10.15)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.19.1->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/94/e7/c250d122992e1561690d9c0f7856dadb79d61fd4bdd0e598087dce607f6c/requests_oauthlib-1.0.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl\n",
      "Collecting azure-cli-command-modules-nspkg>=2.0.0 (from azure-cli-profile>=2.0.26->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/c9/cdeeeabc550848e2a07caa66cba28aa057d23b6feaa824ceafd32c3f2226/azure_cli_command_modules_nspkg-2.0.2-py2.py3-none-any.whl\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting portalocker==1.2.1 (from azure-cli-telemetry->azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/57/41/05e79e5516db1cc0c967b3202388cde729f871c871b0a07bf24ff11adfcf/portalocker-1.2.1-py2.py3-none-any.whl\n",
      "Collecting bcrypt>=3.1.3 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/09/905ec939994e2c49dcffff72f823802557f166b3815ea54c1db3671eed42/bcrypt-3.1.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pynacl>=1.0.1 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl\n",
      "Collecting pycparser (from cffi!=1.11.3,>=1.7->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==0.1.74.*->azureml-defaults==0.1.74->-r /tmp/azureml_runs/matsu_test1116_02_1542332931636/azureml-setup/condaenv.v6lpJe.requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/d1/ddd9cfea3e736399b97ded5c2dd62d1322adef4a72d816f1ed1049d6a179/oauthlib-2.1.0-py2.py3-none-any.whl\n",
      "Installing collected packages: applicationinsights, portalocker, azure-nspkg, azure-cli-nspkg, azure-cli-telemetry, argcomplete, jmespath, pygments, tabulate, pyyaml, colorama, knack, azure-common, PyJWT, python-dateutil, idna, pycparser, cffi, asn1crypto, cryptography, urllib3, chardet, requests, adal, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-mgmt-nspkg, azure-mgmt-resource, humanfriendly, antlr4-python3-runtime, wheel, bcrypt, pynacl, pyasn1, paramiko, pyopenssl, azure-cli-core, azure-mgmt-keyvault, ruamel.yaml, azure-storage-nspkg, websocket-client, docker-pycreds, docker, azure-mgmt-storage, jsonpickle, azure-mgmt-containerregistry, ndg-httpsclient, azure-mgmt-authorization, azure-graphrbac, azure-storage-common, azure-storage-blob, SecretStorage, azure-cli-command-modules-nspkg, azure-cli-profile, backports.weakref, backports.tempfile, pytz, contextlib2, pathspec, azureml-core, azureml-defaults\n",
      "  Found existing installation: wheel 0.32.2\n",
      "    Uninstalling wheel-0.32.2:\n",
      "      Successfully uninstalled wheel-0.32.2\n",
      "Successfully installed PyJWT-1.6.4 SecretStorage-2.3.1 adal-1.2.0 antlr4-python3-runtime-4.7.1 applicationinsights-0.11.7 argcomplete-1.9.4 asn1crypto-0.24.0 azure-cli-command-modules-nspkg-2.0.2 azure-cli-core-2.0.50 azure-cli-nspkg-3.0.3 azure-cli-profile-2.1.2 azure-cli-telemetry-1.0.0 azure-common-1.1.16 azure-graphrbac-0.52.0 azure-mgmt-authorization-0.51.0 azure-mgmt-containerregistry-2.4.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-2.0.0 azure-mgmt-storage-3.1.0 azure-nspkg-3.0.2 azure-storage-blob-1.4.0 azure-storage-common-1.4.0 azure-storage-nspkg-3.1.0 azureml-core-0.1.74 azureml-defaults-0.1.74 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.1.4 cffi-1.11.5 chardet-3.0.4 colorama-0.4.0 contextlib2-0.5.5 cryptography-2.4.1 docker-3.5.1 docker-pycreds-0.3.0 humanfriendly-4.17 idna-2.7 isodate-0.6.0 jmespath-0.9.3 jsonpickle-1.0 knack-0.4.5 msrest-0.6.1 msrestazure-0.5.1 ndg-httpsclient-0.5.1 oauthlib-2.1.0 paramiko-2.4.2 pathspec-0.5.9 portalocker-1.2.1 pyasn1-0.4.4 pycparser-2.19 pygments-2.2.0 pynacl-1.3.0 pyopenssl-18.0.0 python-dateutil-2.7.5 pytz-2018.7 pyyaml-3.13 requests-2.20.1 requests-oauthlib-1.0.0 ruamel.yaml-0.15.51 tabulate-0.8.2 urllib3-1.23 websocket-client-0.54.0 wheel-0.30.0\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\n",
      "\n",
      "__init__() got an unexpected keyword argument 'encoding'\n",
      "\n",
      "Encountered an error while trying to add the AzureML managed conda environment directory to the user's conda configuration.\n",
      "You can manually add the AzureML managed conda environment directory to your conda config by running:\n",
      "conda config --append envs_dirs /home/azureuser/.azureml/envs\n",
      "\n",
      "Or by manually editing the .condarc file located in your home directory and adding the following:\n",
      "envs_dirs:\n",
      "  - /home/azureuser/.azureml/envs\n",
      "\n",
      "Running: ['/home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/bin/python', 'azureml-setup/run_script.py', '/home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/bin/python', 'azureml-setup/context_manager_injector.py', '-i', 'ProjectPythonPath:context_managers.ProjectPythonPath', '-i', 'DataStoreCopy:context_managers.DataStores', '-i', 'OutputCollection:context_managers.RunHistory', 'train.py', '--data_folder', 'myblob01/tfdata']\n",
      "Logging experiment running status in history service.\n",
      "Streaming log file azureml-logs/80_driver_log.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "WARNING:tensorflow:From train.py:187: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "WARNING:tensorflow:From train.py:25: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From train.py:26: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From train.py:40: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "2018-11-16 01:54:14.039477: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2018-11-16 01:54:20.168347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 538e:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2018-11-16 01:54:20.168389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-11-16 01:54:20.469480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-11-16 01:54:20.469532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-11-16 01:54:20.469541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-11-16 01:54:20.469797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 538e:00:00.0, compute capability: 3.7)\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2018-11-16 01:54:37.723313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-11-16 01:54:37.723359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-11-16 01:54:37.723369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-11-16 01:54:37.723374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-11-16 01:54:37.723485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 538e:00:00.0, compute capability: 3.7)\n",
      "2018-11-16 01:54:39.507377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-11-16 01:54:39.507443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-11-16 01:54:39.507453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-11-16 01:54:39.507459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-11-16 01:54:39.507590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 538e:00:00.0, compute capability: 3.7)\n",
      "WARNING:tensorflow:From /home/azureuser/.azureml/envs/azureml_eb285141a68f96e69ee8e8721c7c9e30/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "current working directory is  /tmp/azureml_runs/matsu_test1116_02_1542332931636\n",
      "model is saved  b'./outputs/1542333279'\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: matsu_test1116_02_1542332931636\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'matsu_test1116_02_1542332931636',\n",
       " 'target': 'mydsvm01',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2018-11-16T01:54:06.743491Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'dcb2178c-8836-4c1d-b0d4-480e97b9c5f5'},\n",
       " 'runDefinition': {'Script': 'train.py',\n",
       "  'Arguments': ['--data_folder', '$AZUREML_DATAREFERENCE_myblob01'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'mydsvm01',\n",
       "  'DataReferences': {'myblob01': {'DataStoreName': 'myblob01',\n",
       "    'Mode': 'Download',\n",
       "    'PathOnDataStore': 'tfdata',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': True}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults==0.1.74']},\n",
       "      'tensorflow-gpu']},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.1.4',\n",
       "    'Enabled': False,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'Location': None,\n",
       "   'RetainCluster': False,\n",
       "   'NodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 1, 'MemoryGb': 4},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mlws014885792189.blob.core.windows.net/azureml/ExperimentRun/matsu_test1116_02_1542332931636/azureml-logs/60_control_log.txt?sv=2017-04-17&sr=b&sig=oa%2Fo4JwHLUSakIHasUcZbMwUgy97zjlyaor9VOuwfIQ%3D&st=2018-11-16T01%3A44%3A42Z&se=2018-11-16T09%3A54%3A42Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://mlws014885792189.blob.core.windows.net/azureml/ExperimentRun/matsu_test1116_02_1542332931636/azureml-logs/80_driver_log.txt?sv=2017-04-17&sr=b&sig=DkRl7JmXpsUGDVpShqNxyzJAqccuMFEXiO3N6DbraI8%3D&st=2018-11-16T01%3A44%3A42Z&se=2018-11-16T09%3A54%3A42Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://mlws014885792189.blob.core.windows.net/azureml/ExperimentRun/matsu_test1116_02_1542332931636/azureml-logs/azureml.log?sv=2017-04-17&sr=b&sig=tvAFjADa1rIHgy8B%2FuWpso551IGD%2FeBb3BoVLF%2BjpN8%3D&st=2018-11-16T01%3A44%3A42Z&se=2018-11-16T09%3A54%3A42Z&sp=r'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='train.py',\n",
    "    run_config=run_config,\n",
    "    arguments=['--data_folder', str(ds.as_download())]\n",
    ")\n",
    "exp = Experiment(workspace=ws, name='tf_remote_experiment')\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Download results and check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/60_control_log.txt',\n",
       " 'azureml-logs/80_driver_log.txt',\n",
       " 'logs/events.out.tfevents.1542333253.mydsvm01462390892e8d',\n",
       " 'logs/model.ckpt-0.index',\n",
       " 'logs/model.ckpt-0.meta',\n",
       " 'logs/checkpoint',\n",
       " 'logs/graph.pbtxt',\n",
       " 'logs/model.ckpt-0.data-00000-of-00001',\n",
       " 'logs/model.ckpt-1100.meta',\n",
       " 'logs/model.ckpt-1100.data-00000-of-00001',\n",
       " 'logs/model.ckpt-1100.index',\n",
       " 'logs/eval/events.out.tfevents.1542333279.mydsvm01462390892e8d',\n",
       " 'outputs/1542333279/saved_model.pb',\n",
       " 'outputs/1542333279/variables/variables.data-00000-of-00001',\n",
       " 'outputs/1542333279/variables/variables.index',\n",
       " 'driver_log',\n",
       " 'azureml-logs/azureml.log']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model into your local machine.    \n",
    "**Please change ```1542333279``` to meet previous results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file(\n",
    "    name='outputs/1542333279/saved_model.pb',\n",
    "    output_file_path='remote_model/saved_model.pb')\n",
    "run.download_file(\n",
    "    name='outputs/1542333279/variables/variables.data-00000-of-00001',\n",
    "    output_file_path='remote_model/variables/variables.data-00000-of-00001')\n",
    "run.download_file(\n",
    "    name='outputs/1542333279/variables/variables.index',\n",
    "    output_file_path='remote_model/variables/variables.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict your test data using downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./remote_model/variables/variables\n",
      "Predicted:  [7, 2, 1]\n",
      "Actual   :  [7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Read data by tensor\n",
    "dataset = tf.data.TFRecordDataset('./data/test.tfrecords')\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "data_org = iterator.get_next()\n",
    "data_exam = tf.parse_single_example(\n",
    "    data_org,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "data_image.set_shape([784])\n",
    "data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "\n",
    "# Run tensor and generate data\n",
    "with tf.Session() as sess:\n",
    "    image_arr = []\n",
    "    label_arr = []\n",
    "    for i in range(3):\n",
    "        image, label = sess.run([data_image, data_label])\n",
    "        image_arr.append(image)\n",
    "        label_arr.append(label)\n",
    "\n",
    "# Predict\n",
    "pred_fn = tf.contrib.predictor.from_saved_model('./remote_model')\n",
    "pred = pred_fn({'inputs': image_arr})\n",
    "\n",
    "print('Predicted: ', pred['classes'].tolist())\n",
    "print('Actual   : ', label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Remove VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvm_compute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
