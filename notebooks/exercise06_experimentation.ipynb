{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise06 : Experimentation Logs and Outputs\n",
    "\n",
    "Here we add logging capabilities in our source code, and run / check.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/Readme.md)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workspace setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/tsmatsuz/Tutorial/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='experiment_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change your source code and Train\n",
    "\n",
    "Change your source code in \"[Exercise03 : Just Train in Your Working Machine](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/notebooks/exercise03_train_simple.ipynb)\" for logging in AML as follows. (The lines commented \"##### Modified\" are modified lines.)    \n",
    "After running, let's go to [Azure Portal](https://portal.azure.com/) and see how logs look like in AML experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbf77577128>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './logs'}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3147962, step = 1\n",
      "INFO:tensorflow:global_step/sec: 42.2733\n",
      "INFO:tensorflow:loss = 0.5155537, step = 101 (2.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2206\n",
      "INFO:tensorflow:loss = 0.36454296, step = 201 (3.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7858\n",
      "INFO:tensorflow:loss = 0.28836393, step = 301 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.4546\n",
      "INFO:tensorflow:loss = 0.5169686, step = 401 (1.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1181\n",
      "INFO:tensorflow:loss = 0.28233996, step = 501 (1.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.718\n",
      "INFO:tensorflow:loss = 0.32613716, step = 601 (2.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.132\n",
      "INFO:tensorflow:loss = 0.35053828, step = 701 (2.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.3094\n",
      "INFO:tensorflow:loss = 0.24950473, step = 801 (1.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.2361\n",
      "INFO:tensorflow:loss = 0.22871317, step = 901 (1.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.8529\n",
      "INFO:tensorflow:loss = 0.25021386, step = 1001 (1.789 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into ./logs/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-16-11:28:26\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-16-11:28:30\n",
      "INFO:tensorflow:Saving dict for global step 1100: accuracy = 0.9304, global_step = 1100, loss = 0.22836469\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1100: ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Loss for final step: 0.28881735.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model.ckpt-1100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./outputs/temp-b'1542367710'/saved_model.pb\n",
      "current working directory is  /data/home/tsmatsuz/Tutorial\n",
      "model is saved  b'./outputs/1542367710'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AsyncTask(post)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core.run import Run ##### Modified\n",
    "\n",
    "# Get run when running in remote ##### Modified\n",
    "if 'run' not in locals(): ##### Modified\n",
    "    run = Run.get_context() ##### Modified\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        # Ask for accuracy and loss in each steps ##### Modified\n",
    "        class _CustomLoggingHook(tf.train.SessionRunHook): ##### Modified\n",
    "            def begin(self): ##### Modified\n",
    "                self.training_accuracy = [] ##### Modified\n",
    "                self.training_loss = [] ##### Modified\n",
    "            def before_run(self, run_context): ##### Modified\n",
    "                return tf.train.SessionRunArgs([accuracy[1], loss, global_step]) ##### Modified\n",
    "            def after_run(self, run_context, run_values): ##### Modified\n",
    "                result_accuracy, result_loss, result_step = run_values.results ##### Modified\n",
    "                #run.log('training_accuracy', result_accuracy) ##### Modified\n",
    "                #run.log('training_loss', result_loss) ##### Modified\n",
    "                self.training_accuracy.append(result_accuracy) ##### Modified\n",
    "                self.training_loss.append(result_loss) ##### Modified\n",
    "                if result_step % 100 == 0 : # save logs in each 100 steps ##### Modified\n",
    "                    run.log_list('training_accuracy', self.training_accuracy) ##### Modified\n",
    "                    run.log_list('training_loss', self.training_loss) ##### Modified\n",
    "                    self.training_accuracy = [] ##### Modified\n",
    "                    self.training_loss = [] ##### Modified\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            training_chief_hooks=[_CustomLoggingHook()], ##### Modified\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.contrib.learn.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "eval_res = tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)\n",
    "\n",
    "# send logs to AML ##### Modified   \n",
    "run.log('learning_rate', FLAGS.learning_rate) ##### Modified\n",
    "run.log('1st_layer', FLAGS.first_layer) ##### Modified\n",
    "run.log('2nd_layer', FLAGS.second_layer) ##### Modified\n",
    "run.log('final_accuracy', eval_res[0]['accuracy']) ##### Modified\n",
    "run.log('final_loss', eval_res[0]['loss']) ##### Modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show logs using AML run history widget\n",
    "\n",
    "You can also view your logs in your notebook. (For viewing in your notebook, you must install extensions on your jupyter server. See [Readme](https://github.com/tsmatz/azure-ml-tensorflow-complete-sample/Readme.md).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5453c5225d440a2a0eff0a576e53c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run_instance=run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by code\n",
    "\n",
    "You can also explorer using python code and plot as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfa48286a0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "metrics = run.get_metrics()\n",
    "plt.plot(metrics['training_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
